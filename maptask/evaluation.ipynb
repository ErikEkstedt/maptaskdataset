{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "These are some initial results from training a simple multilayerd\n",
    "lstm model on\n",
    "the task of generating the acoustic feature output for the next\n",
    "frame.\n",
    "\n",
    "The model was trained on **the entire** dataset as a start to see if\n",
    "doing this\n",
    "with a vanilla multilayered lstm using MSELoss would be feasible.\n",
    "The\n",
    "dataset consists of **4812** datapoints. Each datum consists of 152 frames\n",
    "with\n",
    "4 values as input and 2 targets for each frame. These values correlate for\n",
    "the\n",
    "pitch and intensity values for the speaker, the listener and the the target\n",
    "output for the listener in the subsequent frame, resectively.\n",
    "\n",
    "The model used is simply a multilayered lstm with n layers, h hidden nodes, and\n",
    "a fully connected output layer mapping the hidden state size to the desired\n",
    "output dimensions.  Training consisted of training the model for 100 epochs on\n",
    "the dataset with `h=64` and `n=[1,2,5,10,15,20]`. The lstm trained on the entire\n",
    "152 element long sequence for each backpropagation and was optimized using Adam\n",
    "(lr=0.001) on the mean squared error loss.\n",
    "\n",
    ":bulb: **Warning** This was accidentally trained with forced teaching on the\n",
    "entire sequence. The best model in the absent of this had the same behavior\n",
    "irrelevant of input.\n",
    "\n",
    "The best loss came from using 5 layers.\n",
    "\n",
    "<img width=\"200\" src='images/basic_lstm_5_layer_loss.png' alt=\"training\" >\n",
    "\n",
    "Here is a [link](http://130.237.67.222:6007/#scalars) to the complete training\n",
    "output in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'maptask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71a5a4ede9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaptask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaptask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicLstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'maptask'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from maptask.dataset import DSet\n",
    "from maptask.models import BasicLstm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def plot(out, target):\n",
    "    pitch = out[0].numpy()\n",
    "    intensity = out[1].numpy()\n",
    "    target_pitch = target[0].numpy()\n",
    "    target_intensity = target[1].numpy()\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('Pitch')\n",
    "    plt.plot(pitch, 'b', label='Predicted')\n",
    "    plt.plot(target_pitch, 'r', label='Target')\n",
    "    plt.legend()\n",
    "    plt.xlabel('frames')\n",
    "    plt.ylabel('frequency', color='k')\n",
    "    plt.tick_params('y', colors='k')\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title('Intensity')\n",
    "    plt.plot(intensity, 'b', label='Predicted')\n",
    "    plt.plot(target_intensity, 'r', label='Target')\n",
    "    plt.legend()\n",
    "    plt.ylabel('intensity', color='k')\n",
    "    plt.tick_params('frames', colors='k')\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "\n",
    "# Data\n",
    "dset = DSet()\n",
    "dloader = DataLoader(dset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Load model\n",
    "model_path = 'checkpoints/basiclstm_l5_best.pt'\n",
    "\n",
    "print('Loading model: ', model_path)\n",
    "model = torch.load(model_path)\n",
    "model.lstm.flatten_parameters()\n",
    "model.eval()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Iterate through data set comparing predictions with target: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot target and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = dset.get_random()\n",
    "inp = inp.unsqueeze(0).to(device)\n",
    "out = model(inp).squeeze()\n",
    "plot(out.cpu().detach(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = dset.get_random()\n",
    "inp = inp.unsqueeze(0).to(device)\n",
    "out = model(inp).squeeze()\n",
    "plot(out.cpu().detach(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = dset.get_random()\n",
    "inp = inp.unsqueeze(0).to(device)\n",
    "out = model(inp).squeeze()\n",
    "plot(out.cpu().detach(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = dset.get_random()\n",
    "inp = inp.unsqueeze(0).to(device)\n",
    "out = model(inp).squeeze()\n",
    "plot(out.cpu().detach(), target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
