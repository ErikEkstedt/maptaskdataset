{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming\n",
    "\n",
    "## Utils\n",
    "\n",
    "<strong>TODO: These are all inputs from utils some are note needed anymore </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists\n",
    "from scipy.io.wavfile import read, write\n",
    "from subprocess import call\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies and set sounddevice sample rate to 20000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import random\n",
    "import time\n",
    "\n",
    "sd.default.samplerate = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "Useful script to load a custom data path or generic which I try to use across systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths():\n",
    "    # Assumes maptask dialogue files are downloaded in $dataPath\n",
    "    try:\n",
    "        full_path = os.path.realpath(__file__)\n",
    "        path, filename = os.path.split(full_path)\n",
    "    except: # for ipython repl error\n",
    "        path = os.path.realpath(os.getcwd())\n",
    "    data_path = os.path.realpath(join(path, 'data'))\n",
    "    timed_units_path = join(data_path, \"maptaskv2-1/Data/timed-units\")\n",
    "    return {'data_path' : data_path,\n",
    "            'annotation_path' : join(data_path, 'maptaskv2-1'),\n",
    "            'dialog_path' : join(data_path, 'dialogues'),\n",
    "            'mono_path' : join(data_path, 'dialogues_mono'),\n",
    "            'gemap_path' : join(data_path, 'gemaps'),\n",
    "            'opensmile_path' : os.path.realpath(join(path, '..', '..', 'opensmile/opensmile-2.3.0'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the paths to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialog path:  /home/erik/maptaskdataset/notes/data/dialogues\n",
      "annotation path:  /home/erik/maptaskdataset/notes/data/maptaskv2-1\n",
      "mono path:  /home/erik/maptaskdataset/notes/data/dialogues_mono\n"
     ]
    }
   ],
   "source": [
    "paths = get_paths()\n",
    "dialog_path = paths['dialog_path']\n",
    "annotation_path = paths['annotation_path']\n",
    "mono_path = paths['mono_path']\n",
    "print('dialog path: ', dialog_path)\n",
    "print('annotation path: ', annotation_path)\n",
    "print('mono path: ', mono_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get time stamp and utterences\n",
    "\n",
    "\n",
    "//// \n",
    "\n",
    "--------------\n",
    "\n",
    "\\[[doc string in function should become this intro text](todoipynb)\n",
    "Make a programming with gitsubmodules. like vim programming-eco-system. \\]\n",
    "\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_filename_utterence(name, annotation_path, pause_time=1):\n",
    "    '''\n",
    "    Arguments\n",
    "    ---------\n",
    "\n",
    "    :name                   session name (string)\n",
    "    :timed_units_path       path to timed-units annotaions (string)\n",
    "    :pause_time             pause length in sexonds to define discrete utterences (int)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "\n",
    "    :tu_data                (list) of dicts containing time, name and utterence.\n",
    "\n",
    "    a dict contains:\n",
    "        dict['time'] = (start,end)\n",
    "        dict['name'] = q1ec1-0001\n",
    "        dict['utterence'] = 'hello my name is'\n",
    "    '''\n",
    "    tu_data = []\n",
    "    # name = name[:-4]  # remove .wav\n",
    "\n",
    "    tmp_dict = extract_tag_data(name, annotation_path)\n",
    "\n",
    "    # Extract time and word annotations for utterences seperated by at least\n",
    "    # :pause_time (seconds)\n",
    "    i, start, end = 0, 0, 0\n",
    "    tmp_utterence = ''\n",
    "    for j, (t, w) in enumerate(zip(tmp_dict['tu'], tmp_dict['words'])):\n",
    "        pause = t[0] - end  # pause since last word\n",
    "        if pause < pause_time:\n",
    "            if j == 0:\n",
    "                tmp_utterence += w\n",
    "            else:\n",
    "                tmp_utterence += ' ' + w\n",
    "                end = t[1]\n",
    "        else:\n",
    "            utterence = tmp_utterence\n",
    "            time = (start, end)\n",
    "            tmp_name = name + '-{0:04}'.format(i)\n",
    "            tu_data.append({'time':time, 'name':tmp_name, 'words': utterence})\n",
    "            i += 1\n",
    "            start, end = t\n",
    "            tmp_utterence = w\n",
    "    return tu_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maptask to Tacotron\n",
    "\n",
    "Given up idea of tacotron but rewrote code to store data as stored for tacotron.\n",
    "\n",
    "Not pursuing anymore for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maptask_to_tacotron(output_path,\n",
    "                        timed_units_path,\n",
    "                        mono_path,\n",
    "                        pause_time=1,\n",
    "                        sr=20000):\n",
    "    '''\n",
    "    This script should extract the text and audio part of utterences seperated\n",
    "    by $pause_time from $person in the Maptask dataset.\n",
    "\n",
    "    The audio snippets is cut out and stored as wav-files with a name\n",
    "    according to (ex: q1ec1-0001, q1ec1-0002, ...).\n",
    "\n",
    "    Each line in the produces txt-file has the following form:\n",
    "\n",
    "    name_of_audio|utterence (string)\n",
    "    name_of_audio|utterence (string)\n",
    "    '''\n",
    "    mono_file_names = os.listdir(mono_path)\n",
    "    mono_file_names.sort()  # Nice to do in order when debugging\n",
    "\n",
    "    file_txt = join(output_path, 'maptask')\n",
    "    file_f = open(file_txt+'.f.txt', \"w\")\n",
    "    file_g = open(file_txt+'.g.txt', \"w\")\n",
    "\n",
    "    wavs_path = join(output_path, 'wavs')\n",
    "    if not exists(wavs_path):\n",
    "        pathlib.Path(wavs_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Iterate through all (mono) audiofiles, chop the audio in to utterences\n",
    "    for mono_wav in tqdm(mono_file_names):\n",
    "        if '.wav' in mono_wav:  # failsafe\n",
    "            # mono_wav: q1ec1.f.wav, q1ec1.g.wav, ...\n",
    "            fpath = join(mono_path, mono_wav) # Full path to file\n",
    "\n",
    "            # Load audio file\n",
    "            sr, y = read(fpath)\n",
    "\n",
    "            # get time and words from timed-units\n",
    "            tu_data = get_time_filename_utterence(mono_wav, timed_units_path)\n",
    "\n",
    "            for d in tu_data:\n",
    "                start, end = d['time']  # time\n",
    "                start = librosa.time_to_samples(start, sr=sr)\n",
    "                end = librosa.time_to_samples(end, sr=sr)\n",
    "                y_tmp = y[start:end]\n",
    "\n",
    "                # write chopped audio to disk\n",
    "                tmp_path = join(wavs_path, 'wavs', d['name']+'.wav')\n",
    "                write(filename=tmp_path, rate=sr, data=y_tmp)\n",
    "\n",
    "                # write corresponding row in txt\n",
    "                s = d['name'] + '|' + d['words'] + '\\n'\n",
    "                if '.f.' in mono_wav:\n",
    "                    file_f.write(s)\n",
    "                else:\n",
    "                    file_g.write(s)\n",
    "    file_f.close()\n",
    "    file_g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get paths\n",
    "\n",
    "This one is helpful and could be booilerplate in all code.\n",
    "A function that could use a custom path or go to standard.\n",
    "\n",
    "\n",
    "## create data points \n",
    "\n",
    "Input the session name you need time data from, the annotation\\_path and a user\n",
    "(optional), either 'f' for follower or 'g' for guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_points(session_name, annotation_path, user='f'):\n",
    "  print(session_name)\n",
    "  # load timed-units.xml\n",
    "  timed_units_path = join(annotation_path, 'Data/timed-units')\n",
    "  for f in os.listdir(timed_units_path):\n",
    "\tif session_name in f and '.'+user+'.' in f:\n",
    "  print(f)\n",
    "  user_data = get_time_filename_utterence(f, annotation_path, pause_time=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
