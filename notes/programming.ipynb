{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming\n",
    "\n",
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "Useful script to load a custom data path or generic which I try to use\n",
    "across systems.\n",
    "\n",
    "This one is helpful and could be booilerplate in all code.\n",
    "A\n",
    "function that could use a custom path or go to standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(root_path=None):\n",
    "    # Assumes maptask dialogue files are downloaded in $dataPath\n",
    "    if not root_path:\n",
    "        try:\n",
    "            full_path = os.path.realpath(__file__)\n",
    "            root_path, filename = os.path.split(full_path)\n",
    "        except: # for ipython repl error\n",
    "            print('Assumes this repo is in home directory')\n",
    "            root_path = join(os.path.expanduser('~'), 'maptaskdataset')\n",
    "    data_path = os.path.realpath(join(root_path, 'data'))\n",
    "    return {'data_path' : data_path,\n",
    "            'annotation_path' : join(data_path, 'maptaskv2-1'),\n",
    "            'dialog_path' : join(data_path, 'dialogues'),\n",
    "            'mono_path' : join(data_path, 'dialogues_mono'),\n",
    "            'timed_units_path': join(data_path, \"maptaskv2-1/Data/timed-units\"),\n",
    "            'gemap_path' : join(data_path, 'gemaps'),\n",
    "            'opensmile_path' : join(os.path.expanduser('~'), 'opensmile-2.3.0')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract tag data from xml path\n",
    "\n",
    "Given an xml-path extract annotated timed-\n",
    "units data. The annotations includes time-units for words spoken, silence and\n",
    "random noise. \n",
    "\n",
    "The data is returned as a dict containing the spoken words,\n",
    "their timings, the times for noise and silence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tag_data_from_xml_path(xml_path):\n",
    "    '''\n",
    "    Extract timed-unit (tu), silence (si) and noise (noi) tags from the\n",
    "    .xml annotation file.\n",
    "    '''\n",
    "    # parse xml\n",
    "    xml_element_tree = ET.parse(xml_path)\n",
    "\n",
    "    tu, words, sil, noi = [], [], [], []\n",
    "    for elem in xml_element_tree.iter():\n",
    "        try:\n",
    "            tmp = (float(elem.attrib['start']), float(elem.attrib['end']))\n",
    "        except:\n",
    "            continue\n",
    "        if elem.tag == 'tu':\n",
    "            # elem.attrib: start, end, utt\n",
    "            words.append(elem.text)  # word annotation\n",
    "            tu.append(tmp)\n",
    "        elif elem.tag == 'sil':\n",
    "            # elem.attrib: start, end\n",
    "            sil.append(tmp)\n",
    "        elif elem.tag == 'noi':\n",
    "            # elem.attrib: start, end, type='outbreath/lipsmack/...'\n",
    "            noi.append(tmp)\n",
    "    return {'tu': tu, 'silence': sil, 'noise': noi, 'words': words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timing_utterences(name,\n",
    "                          user='f',\n",
    "                          pause_time=1,\n",
    "                          pre_padding=0,\n",
    "                          post_padding=0,\n",
    "                          timed_units_path=None):\n",
    "\n",
    "    def merge_pauses(tu, words, threshold=0.1):\n",
    "        new_tu, new_words = [], []\n",
    "        start, last_end, tmp_words = 0, 0, []\n",
    "\n",
    "        for i, (t, w) in enumerate(zip(tu, words)):\n",
    "            # t[0] - start,  t[1] - end\n",
    "            pause_duration = t[0] - last_end\n",
    "            if pause_duration > threshold:\n",
    "                new_tu.append((start, last_end))\n",
    "                new_words.append(tmp_words)\n",
    "                tmp_words = [w]\n",
    "                start = t[0]\n",
    "                last_end = t[1]\n",
    "            else:\n",
    "                tmp_words.append(w)\n",
    "                last_end = t[1]\n",
    "        return new_tu[1:], new_words[1:]  # remove first entry which is always zero\n",
    "\n",
    "    if not timed_units_path:\n",
    "        timed_units_path = get_paths()['timed_units_path']\n",
    "\n",
    "    # load timed-units.xml. Searching through dir.\n",
    "    for file in os.listdir(timed_units_path):\n",
    "        if name in file:\n",
    "            if '.'+user+'.' in file:\n",
    "                xml_path = join(timed_units_path, file)\n",
    "\n",
    "    data = extract_tag_data_from_xml_path(xml_path)\n",
    "    times, words = merge_pauses(data['tu'], data['words'])\n",
    "\n",
    "    # Pad utterence to include context\n",
    "    if pre_padding or post_padding:\n",
    "        t = np.array(times)\n",
    "        t += (-pre_padding, post_padding)\n",
    "        times = t\n",
    "\n",
    "    samples = librosa.time_to_samples(times, sr=20000)\n",
    "\n",
    "    return [{'time':time, 'sample': sample, 'words': word} \\\n",
    "            for time, sample, word in zip(times, samples, words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utterences(all_sessions_data, utterence_length=1):\n",
    "    utterence_data, vocab = [], {}\n",
    "    for session in all_sessions_data:\n",
    "        tmp_session_data = []\n",
    "        session_data = session['data']\n",
    "        for utterence in session_data:\n",
    "            utter = utterence['words']\n",
    "            if len(utter) <= utterence_length:\n",
    "                tmp_session_data.append(utterence)\n",
    "                if not utter[0] in vocab.keys():\n",
    "                    vocab[utter[0]] = 1\n",
    "                else:\n",
    "                    vocab[utter[0]] += 1\n",
    "        utterence_data.append({'name': session['name'],\n",
    "                                    'data': tmp_session_data})\n",
    "    return utterence_data, vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find how many backchannels present in maptask\n",
    "\n",
    "1. Get all session name in\n",
    "maptask audio folder\n",
    "2. Extract all timing and word data from each session\n",
    "(entire dataset)\n",
    "3. Get all one word utterences\n",
    "4. Look at one word vocab and\n",
    "extract backchannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumes this repo is in home directory\n",
      "dialog path:  /Users/erik/maptaskdataset/data/dialogues\n",
      "annotation path:  /Users/erik/maptaskdataset/data/maptaskv2-1\n",
      "mono path:  /Users/erik/maptaskdataset/data/dialogues_mono\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "paths = get_paths()\n",
    "\n",
    "session_names = [fname.split('.')[0] for fname in \\\n",
    "                 os.listdir(paths['dialog_path']) if fname.endswith('.wav')]\n",
    "\n",
    "print('dialog path: ', paths['dialog_path'])\n",
    "print('annotation path: ', paths['annotation_path'])\n",
    "print('mono path: ', paths['mono_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all short utterences for the follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 222.51it/s]\n"
     ]
    }
   ],
   "source": [
    "user = 'f'\n",
    "all_f_data = []\n",
    "for name in tqdm(session_names):\n",
    "    session_data = get_timing_utterences(name,\n",
    "                                         user=user,\n",
    "                                         pause_time=0.2,\n",
    "                                         pre_padding=0,\n",
    "                                         post_padding=0,\n",
    "                                         timed_units_path=paths['timed_units_path'])\n",
    "    all_f_data.append({'name': name, 'data':session_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all short utterences for the guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 139.64it/s]\n"
     ]
    }
   ],
   "source": [
    "user = 'g'\n",
    "all_g_data = []\n",
    "for name in tqdm(session_names):\n",
    "    session_data = get_timing_utterences(name,\n",
    "                                         user=user,\n",
    "                                         pause_time=0.2,\n",
    "                                         pre_padding=0,\n",
    "                                         post_padding=0,\n",
    "                                         timed_units_path=paths['timed_units_path'])\n",
    "    all_g_data.append({'name': name, 'data':session_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follower Vocab:\n",
      "('right', 1543)\n",
      "('okay', 736)\n",
      "('mmhmm', 710)\n",
      "('uh-huh', 677)\n",
      "('yeah', 533)\n",
      "('no', 278)\n",
      "('yes', 116)\n",
      "('mm', 75)\n",
      "('aye', 62)\n",
      "('ehm', 51)\n"
     ]
    }
   ],
   "source": [
    "f_small_utterences, f_vocab = get_utterences(all_f_data, utterence_length=1)\n",
    "g_small_utterences, g_vocab = get_utterences(all_g_data, utterence_length=1)\n",
    "\n",
    "f_vocab = sorted(f_vocab.items(), key=lambda t: t[1], reverse=True)\n",
    "g_vocab = sorted(g_vocab.items(), key=lambda t: t[1], reverse=True)\n",
    "\n",
    "print('Follower Vocab:')\n",
    "for entry in f_vocab[:10]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guide Vocab:\n",
      "('right', 1036)\n",
      "('okay', 528)\n",
      "('yeah', 409)\n",
      "('uh-huh', 405)\n",
      "('ehm', 356)\n",
      "('no', 281)\n",
      "('and', 174)\n",
      "('eh', 163)\n",
      "('now', 152)\n",
      "('mmhmm', 144)\n"
     ]
    }
   ],
   "source": [
    "print('Guide Vocab:')\n",
    "for entry in g_vocab[:10]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guide:\n",
      "Datapoints:  2734\n",
      "Vocab:  ['right', 'okay', 'yeah', 'uh-huh', 'ehm']\n",
      "Follower:\n",
      "Datapoints:  4199\n",
      "Vocab:  ['right', 'okay', 'mmhmm', 'uh-huh', 'yeah']\n"
     ]
    }
   ],
   "source": [
    "f_dpoints, f_back = 0, []\n",
    "for i in range(5):\n",
    "    f_back.append(f_vocab[i][0])\n",
    "    f_dpoints += f_vocab[i][1]\n",
    "\n",
    "g_dpoints, g_back = 0, []\n",
    "for i in range(5):\n",
    "    g_back.append(g_vocab[i][0])\n",
    "    g_dpoints += g_vocab[i][1]\n",
    "\n",
    "print('Guide:')\n",
    "print('Datapoints: ', g_dpoints)\n",
    "print('Vocab: ', g_back)\n",
    "\n",
    "print('Follower:')\n",
    "print('Datapoints: ', f_dpoints)\n",
    "print('Vocab: ', f_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
